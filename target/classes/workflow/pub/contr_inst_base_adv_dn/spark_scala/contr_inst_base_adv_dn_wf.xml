<?xml version="1.0" encoding="UTF-8"?>
<workflow-app xmlns="uri:oozie:workflow:0.4" name="contr-inst-base-adv-dn-spark-scala-wf">
   <global>
     <job-tracker>${job_tracker}</job-tracker>
     <name-node>${name_node}</name-node>
     <configuration>
       <property>
         <name>tez.queue.name</name>
         <value>${queue_name}</value>
       </property>
       <property>
         <name>mapreduce.job.queuename</name>
         <value>${queue_name}</value>
       </property>
     </configuration>
   </global>
   <credentials>
     <credential name="cred" type="hcat">
       <property>
         <name>hcat.metastore.principal</name>
         <value>${metastorePrincipal}</value>
       </property>
       <property>
         <name>hcat.metastore.uri</name>
         <value>${metaStoreUri}</value>
       </property>
     </credential>
   </credentials>
   <start to="d8-contr-inst-base-adv-dn-pt01-ins" />
   
   <action cred="cred" name="d8-contr-inst-base-adv-dn-pt01-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt01-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt01insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="d8-contr-inst-base-adv-dn-pt02-ins" />
     <error to="fail" />
   </action>
   <action cred="cred" name="d8-contr-inst-base-adv-dn-pt02-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt02-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt02insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="d8-contr-inst-base-adv-dn-pt03-ins" />
     <error to="fail" />
   </action>
   <action cred="cred" name="d8-contr-inst-base-adv-dn-pt03-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt03-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt03insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="d8-contr-inst-base-adv-dn-pt04-ins" />
     <error to="fail" />
   </action>
   <action cred="cred" name="d8-contr-inst-base-adv-dn-pt04-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt04-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt04insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="d8-contr-inst-base-adv-dn-pt05-ins" />
     <error to="fail" />
   </action>
    <action cred="cred" name="d8-contr-inst-base-adv-dn-pt05-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt05-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt05insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="d8-contr-inst-base-adv-dn-pt06-ins" />
     <error to="fail" />
   </action>
    <action cred="cred" name="d8-contr-inst-base-adv-dn-pt06-ins">
     <spark xmlns="uri:oozie:spark-action:0.2">
       <job-tracker>${job_tracker}</job-tracker>
       <name-node>${name_node}</name-node>
       <master>${master}</master>
       <mode>${mode}</mode>
       <name>d8-contr-inst-base-adv-dn-pt06-ins</name>    
       <class>com.ncr.edl.apollo.contr_inst_base_adv_dn.d8contrinstbaseadvdnpt06insRunner</class>
       <jar>${jarHDFSPath}</jar>
       <spark-opts>--queue ${queue_name} --properties-file user.properties ${sparkConfCustom}</spark-opts>
       <arg>${dbParamFileHDFSPath}</arg>
       <arg> ${activityCountRequired}</arg>
     </spark>
     <ok to="end" />
     <error to="fail" />
   </action>
   
   <kill name="fail">
      <message>Error while running workflow contr-inst-base-adv-dn-scala-parallel-wf workflow: [${wf:errorMessage(wf:lastErrorNode())}]</message>
   </kill>
   <end name="end" />
</workflow-app>
