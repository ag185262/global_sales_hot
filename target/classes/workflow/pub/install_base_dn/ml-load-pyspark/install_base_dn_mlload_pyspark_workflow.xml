<?xml version="1.0" encoding="UTF-8"?>
<workflow-app xmlns="uri:oozie:workflow:0.4" name="install-base-dn-ml-load-pyspark-wf">
	<global>
		<job-tracker>${jobTracker}</job-tracker>
	    <name-node>${nameNode}</name-node>
	    <configuration>
	      	<property>
	        	<name>tez.queue.name</name>
        		<value>${queueName}</value>
	      	</property>
	      	<property>
	        	<name>mapreduce.job.queuename</name>
        		<value>${queueName}</value>
	      	</property>
	    </configuration>
	</global>

	<credentials>
		<credential name="prd-cert" type="hcat">
            <property>
                <name>hcat.metastore.uri</name>
                <value>${metaStoreUri}</value>
            </property>
            <property>
                <name>hcat.metastore.principal</name>
                <value>${jdbcPrincipal}</value>
            </property>
        </credential>
	</credentials>

	<start to="fork-node"/>

	<fork name="fork-node">
		<path start = "d8t-cfs-attribute-value-ml-ins"/>
		<path start = "d8t-cfs-extended-attribute-ml-ins"/>
		<path start = "d8t-install-base-item-hist-ml-ins"/>
		<path start = "d8t-install-base-item-ml-ins"/>
		<path start = "d8t-install-base-item-sts-ml-ins"/>
		<path start = "d8t-install-base-vrsn-lbl-ml-ins"/>
	</fork>

	<action cred="prd-cert" name="d8t-cfs-attribute-value-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_cfs_attribute_value_ml_ins</name>
            <jar>d8t_cfs_attribute_value_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<action cred="prd-cert" name="d8t-cfs-extended-attribute-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_cfs_extended_attribute_ml_ins</name>
            <jar>d8t_cfs_extended_attribute_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<action cred="prd-cert" name="d8t-install-base-item-hist-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_install_base_item_hist_ml_ins</name>
            <jar>d8t_install_base_item_hist_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<action cred="prd-cert" name="d8t-install-base-item-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_install_base_item_ml_ins</name>
            <jar>d8t_install_base_item_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<action cred="prd-cert" name="d8t-install-base-item-sts-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_install_base_item_sts_ml_ins</name>
            <jar>d8t_install_base_item_sts_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<action cred="prd-cert" name="d8t-install-base-vrsn-lbl-ml-ins">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>d8t_install_base_vrsn_lbl_ml_ins</name>
            <jar>d8t_install_base_vrsn_lbl_ml_ins.py</jar>
            <spark-opts>
			 --queue ${queueName} --py-files ${py_file} --properties-file user.properties ${sparkConfCustom}
            </spark-opts>
        </spark>
        <ok to="join-node"/>
        <error to="fail"/>
	</action>
	
	<join name = "join-node" to = "end"/>
	
	<kill name="fail">
        	<message>Error in execution of install_base_dn_mlload workflow</message>
	</kill>
	
	<end name="end"/>
	
</workflow-app>
